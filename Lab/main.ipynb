{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c759c9cf",
      "metadata": {},
      "source": [
        "# Check if torch can detect GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "6a217ec4",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU(device_id=0, device=cuda:0)\n",
            "  name:             AMD Radeon Graphics\n",
            "  vram_total_gb:    15.98\n",
            "  vram_free_gb:     15.59\n",
            "  multiprocessors:  30\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "class GPU:\n",
        "    def __init__(self, device_id: int = 0):\n",
        "        self.available = torch.cuda.is_available()\n",
        "        self.device_id = device_id\n",
        "        self.device = torch.device(\"cuda\", device_id) if self.available else torch.device(\"cpu\")\n",
        "        self.name: str | None = None\n",
        "        self.vram_total_gb: float | None = None\n",
        "        self.vram_free_gb: float | None = None\n",
        "        self.multiprocessors: int | None = None\n",
        "\n",
        "        if self.available:\n",
        "            props = torch.cuda.get_device_properties(device_id)\n",
        "            self.name = props.name\n",
        "            self.vram_total_gb = props.total_memory / (1024**3)\n",
        "            self.multiprocessors = props.multi_processor_count\n",
        "            try:\n",
        "                free, _ = torch.cuda.mem_get_info(device_id)\n",
        "                self.vram_free_gb = free / (1024**3)\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "    def __str__(self) -> str:\n",
        "        if not self.available:\n",
        "            return \"GPU(available=False, device=cpu)\"\n",
        "\n",
        "        lines = [\n",
        "            f\"GPU(device_id={self.device_id}, device={self.device})\",\n",
        "            f\"  name:             {self.name}\",\n",
        "            f\"  vram_total_gb:    {self.vram_total_gb:.2f}\",\n",
        "            f\"  vram_free_gb:     {self.vram_free_gb:.2f}\" if self.vram_free_gb is not None else \"  vram_free_gb:     N/A\",\n",
        "            f\"  multiprocessors:  {self.multiprocessors}\",\n",
        "        ]\n",
        "        \n",
        "        return \"\\n\".join(lines)\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        return self.__str__()\n",
        "\n",
        "\n",
        "# Example usage\n",
        "gpu = GPU()\n",
        "print(gpu)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "510fb3ef",
      "metadata": {},
      "source": [
        "# Toy Project\n",
        "A simple toy project to get the basic understanding of the Torch library."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b41dd76e",
      "metadata": {},
      "source": [
        "## Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "d20d8daa",
      "metadata": {},
      "outputs": [],
      "source": [
        "class NeuralNetwork(torch.nn.Module):\n",
        "    def __init__(self, num_inputs: int, num_outputs: int):\n",
        "        super().__init__()\n",
        "\n",
        "        self.layers = torch.nn.Sequential(\n",
        "\n",
        "            # 1st hidden layer\n",
        "            torch.nn.Linear(num_inputs, 30),\n",
        "            torch.nn.ReLU(),\n",
        "\n",
        "            # 2nd hidden layer\n",
        "            torch.nn.Linear(30, 20),\n",
        "            torch.nn.ReLU(),\n",
        "\n",
        "            # Output layer\n",
        "            torch.nn.Linear(20, num_outputs)\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        logits = self.layers(x)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "dcdd6fc2",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[-0.0610,  0.1134, -0.0417]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[0.3115, 0.3709, 0.3176]])\n",
            "tensor(1.)\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "model = NeuralNetwork(num_inputs=50, num_outputs=3)\n",
        "X = torch.randn((1, 50))\n",
        "\n",
        "out = model(X)\n",
        "print(out)\n",
        "\n",
        "with torch.no_grad():\n",
        "    out = torch.softmax(model(X), dim=1)\n",
        "    print(out)\n",
        "    print(sum(out[0])) # class probabilities should sum to 1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e84449b4",
      "metadata": {},
      "source": [
        "## Data Loaders\n",
        "![](../assets/image.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "0a4d6dfe",
      "metadata": {},
      "outputs": [],
      "source": [
        "## Dummy data\n",
        "\n",
        "X_train = torch.tensor([\n",
        "[-1.2, 3.1],\n",
        "[-0.9, 2.9],\n",
        "[-0.5, 2.6],\n",
        "[2.3, -1.1],\n",
        "[2.7, -1.5]\n",
        "])\n",
        "\n",
        "y_train = torch.tensor([0, 0, 0, 1, 1])\n",
        "\n",
        "X_test = torch.tensor([\n",
        "[-0.8, 2.8],\n",
        "[2.6, -1.6],\n",
        "])\n",
        "\n",
        "y_test = torch.tensor([0, 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "7a1481e7",
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class ToyDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.features = X\n",
        "        self.labels = y\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        one_x = self.features[index]\n",
        "        one_y = self.labels[index]\n",
        "        return one_x, one_y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "305c0c48",
      "metadata": {},
      "outputs": [],
      "source": [
        "train_ds = ToyDataset(X_train, y_train)\n",
        "test_ds = ToyDataset(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "91205ffe",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[tensor([[ 2.3000, -1.1000],\n",
            "        [-1.2000,  3.1000]]), tensor([1, 0])]\n",
            "[tensor([[-0.9000,  2.9000],\n",
            "        [ 2.7000, -1.5000]]), tensor([0, 1])]\n",
            "[tensor([[-0.5000,  2.6000]]), tensor([0])]\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    dataset=train_ds,\n",
        "    batch_size=2,\n",
        "    shuffle=True,\n",
        "    num_workers=0,\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    dataset=test_ds,\n",
        "    batch_size=2,\n",
        "    shuffle=False,\n",
        "    num_workers=0,\n",
        ")\n",
        "\n",
        "for batch in train_loader:\n",
        "    print(batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "60c76b54",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 001/003 | Batch 000/003 | Train Loss: 0.75\n",
            "Epoch: 001/003 | Batch 001/003 | Train Loss: 0.65\n",
            "Epoch: 001/003 | Batch 002/003 | Train Loss: 0.42\n",
            "Epoch: 002/003 | Batch 000/003 | Train Loss: 0.05\n",
            "Epoch: 002/003 | Batch 001/003 | Train Loss: 0.13\n",
            "Epoch: 002/003 | Batch 002/003 | Train Loss: 0.00\n",
            "Epoch: 003/003 | Batch 000/003 | Train Loss: 0.01\n",
            "Epoch: 003/003 | Batch 001/003 | Train Loss: 0.00\n",
            "Epoch: 003/003 | Batch 002/003 | Train Loss: 0.02\n"
          ]
        }
      ],
      "source": [
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "torch.manual_seed(123)\n",
        "model = NeuralNetwork(num_inputs=2, num_outputs=2)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.5)\n",
        "\n",
        "num_epochs = 3\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "\n",
        "    for batch_idx, (features, labels) in enumerate(train_loader):\n",
        "        logits = model(features)\n",
        "\n",
        "        loss = F.cross_entropy(logits, labels) # applies softmax internally\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        ### LOGGING\n",
        "        print(f\"Epoch: {epoch+1:03d}/{num_epochs:03d}\"\n",
        "        f\" | Batch {batch_idx:03d}/{len(train_loader):03d}\"\n",
        "        f\" | Train Loss: {loss.item():.2f}\")\n",
        "\n",
        "    model.eval()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "53867c34",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 2.9320, -4.2563],\n",
            "        [ 2.6045, -3.8389],\n",
            "        [ 2.1484, -3.2514],\n",
            "        [-2.1461,  2.1496],\n",
            "        [-2.5004,  2.5210]])\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model(X_train)\n",
        "\n",
        "print(outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "0b111dff",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.9992, 0.0008],\n",
            "        [0.9984, 0.0016],\n",
            "        [0.9955, 0.0045],\n",
            "        [0.0134, 0.9866],\n",
            "        [0.0066, 0.9934]])\n"
          ]
        }
      ],
      "source": [
        "torch.set_printoptions(sci_mode=False)\n",
        "probas = torch.softmax(outputs, dim=1)\n",
        "print(probas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "a8a32014",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0, 0, 0, 1, 1])\n"
          ]
        }
      ],
      "source": [
        "predictions = torch.argmax(probas, dim=1)\n",
        "print(predictions)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "69234697",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([True, True, True, True, True])\n"
          ]
        }
      ],
      "source": [
        "print(predictions == y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "4f44c99c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.)\n"
          ]
        }
      ],
      "source": [
        "def compute_accuracy(model: torch.nn.Module, dataloader: DataLoader):\n",
        "    model = model.eval()\n",
        "    correct = 0.0\n",
        "    total_examples = 0\n",
        "\n",
        "    for idx, (features, labels) in enumerate(dataloader):\n",
        "        with torch.no_grad():\n",
        "            logits = model(features)\n",
        "\n",
        "        predictions = torch.argmax(logits, dim=1)\n",
        "        compare = predictions == labels\n",
        "        correct += torch.sum(compare)\n",
        "        total_examples += len(compare)\n",
        "\n",
        "    return correct / total_examples\n",
        "\n",
        "print(compute_accuracy(model, test_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "bf38aed5",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([5., 7., 9.])\n"
          ]
        }
      ],
      "source": [
        "tensor_1 = torch.tensor([1.0, 2.0, 3.0])\n",
        "tensor_2 = torch.tensor([4.0, 5.0, 6.0])\n",
        "print(tensor_1 + tensor_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "b964889b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([5., 7., 9.], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "tensor_1 = tensor_1.to(\"cuda\")\n",
        "tensor_2 = tensor_2.to(\"cuda\")\n",
        "print(tensor_1 + tensor_2)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv (3.12.12)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
